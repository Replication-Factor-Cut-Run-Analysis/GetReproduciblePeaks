configfile: "config/config.yml"
import pandas as pd
from snakemake.io import glob_wildcards, expand

##################################################################
##                    Define input functions                    ##
##################################################################

# this reads the CSV file and sets an index using the values in the "sample" column.
samples_table = pd.read_csv(config["samples_csv"]).set_index("sample", drop=False)
# convert all values in dataframe to strings
samples_table = samples_table.applymap(str)
# make a samples list
samples_lst = samples_table['sample'].to_list()
# make sets list
sets_lst = set(samples_table['set'].to_list())
# treatmentBam filename input function definition set to Python dictionary
def Bam_dict_from_sample(wildcards):
  return {
    "txBam": samples_table.loc[wildcards.sample, "treatmentBam"],
    "inBam": samples_table.loc[wildcards.sample, "inputBam"]
  }
# function that returns dict of mapped Read Counts filenames/paths joined (ie space-separated) for a set of interest
def CountFiles_dict_from_set(setOfInterest):
  sample_lst = samples_table.loc[samples_table["set"] == str(setOfInterest),"sample"].to_list()
  tx_counts_files_list = expand('results/mappedReadCounts/{sample}_treated_mappedReadCounts.txt', sample = sample_lst)
  in_counts_files_list = expand('results/mappedReadCounts/{sample}_input_mappedReadCounts.txt', sample = sample_lst)
  tx_string = ' '.join([str(item) for item in tx_counts_files_list])
  in_string = ' '.join([str(item) for item in in_counts_files_list])
  return [tx_string, in_string]
# functions that return dicts of bam filenames/paths joined (ie space-separated) for each sample
def Tx_BamFiles_dict_from_samples(sample):
  bam_lst = set(samples_table.loc[samples_table["sample"] == str(sample),"treatmentBam"].to_list())
  return ' '.join([str(item) for item in bam_lst])
def In_BamFiles_dict_from_samples(sample):
  bam_lst = set(samples_table.loc[samples_table["sample"] == str(sample),"inputBam"].to_list())
  return ' '.join([str(item) for item in bam_lst])


##################################################################
##                           rules                              ##
##################################################################

# to run snakemake without explicitly requesting any output files on the command line, we must request output files in the first rule. Therefore we include this otherwise useless rule here  
rule all:
    input:
        expand("results/macs2_normalPeaks/{sample}_" + str(config['macs2_minimum_FDR_cutoff']) + "_peaks.narrowPeak", sample = samples_lst),
        expand("results/mappedReadCounts/{sample}_treated_mappedReadCounts.txt", sample = samples_lst),
        expand("results/mappedReadCounts/{sample}_input_mappedReadCounts.txt", sample = samples_lst),
        expand("results/downSampledBams/{sample}_tx.bam",sample = samples_lst),
        expand("results/downSampledBams/{sample}_in.bam",sample = samples_lst),
        "results/mergedDownSampledBams/" + str(config["experimentName"]) + "_tx.bam",
        "results/mergedDownSampledBams/" + str(config["experimentName"]) + "_in.bam",
        "results/macs2_normalPeaks_merged/" + str(config["experimentName"]) + "_" + str(config['macs2_minimum_FDR_cutoff']) + "_peaks.narrowPeak",

        #expand("results/minMappedReadCounts/{setOfInterest}_treated_minMappedReadCounts.txt", setOfInterest = sets_lst),
        #expand("results/minMappedReadCounts/{setOfInterest}_input_minMappedReadCounts.txt", setOfInterest = sets_lst),
        
# merge technical replicates
rule merge_technical_replicates:
    params:
        tx_technical_replicates = lambda wildcards: Tx_BamFiles_dict_from_samples(wildcards.sample),
        in_technical_replicates = lambda wildcards: In_BamFiles_dict_from_samples(wildcards.sample),
    output:
        tx_merged_bam = "results/mergedTechnicalReplicates/{sample}_tx.bam",
        in_merged_bam = "results/mergedTechnicalReplicates/{sample}_in.bam",
    envmodules: 
        config["samtools"],
    shell:
        """
        samtools merge -@ 8 {output.tx_merged_bam} {params.tx_technical_replicates}
        samtools index -@ 8 {output.tx_merged_bam}
        samtools merge -@ 8 {output.in_merged_bam} {params.in_technical_replicates}
        samtools index -@ 8 {output.in_merged_bam}
        """
        
# call narrow peaks with macs2
rule call_narrow_peaks_with_macs2:
    input:
        tx_merged_bam = "results/mergedTechnicalReplicates/{sample}_tx.bam",
        in_merged_bam = "results/mergedTechnicalReplicates/{sample}_in.bam",
    output:
        "results/macs2_normalPeaks/{sample}_" + str(config['macs2_minimum_FDR_cutoff']) + "_peaks.narrowPeak"
    params:
        effective_genome_size=config["effective_genome_size"],
        minimum_FDR_cutoff=str(config["macs2_minimum_FDR_cutoff"]),
        sample_name="{sample}"
    envmodules:
        config["macs2"]
    log: "results/logs/snakelogs/call_narrow_peaks_with_macs2.{sample}_q" + str(config["macs2_minimum_FDR_cutoff"]) + ".log"
    shell:
        """
        macs2 callpeak -t {input.tx_merged_bam} -c {input.in_merged_bam} -f BAMPE -g {params.effective_genome_size} -n {params.sample_name}_{params.minimum_FDR_cutoff} -q {params.minimum_FDR_cutoff} --outdir results/macs2_normalPeaks/
        """

# write read counts for each bam to a file
rule write_read_counts:
    input:
        tx_merged_bam = "results/mergedTechnicalReplicates/{sample}_tx.bam",
        in_merged_bam = "results/mergedTechnicalReplicates/{sample}_in.bam",
    output:
        treatmentCountFile="results/mappedReadCounts/{sample}_treated_mappedReadCounts.txt",
        inputCountFile="results/mappedReadCounts/{sample}_input_mappedReadCounts.txt",
    envmodules:
        config["samtools"]
    shell:
        """
        samtools idxstats {input.tx_merged_bam} | awk -F '\t' '{{s+=$3}}END{{print s}}' > {output.treatmentCountFile}
        samtools idxstats {input.in_merged_bam} | awk -F '\t' '{{s+=$3}}END{{print s}}' > {output.inputCountFile}
        """
 
# downsample read counts to minimum
rule downsample_min_read_counts:
    input:
        tx_merged_bam = "results/mergedTechnicalReplicates/{sample}_tx.bam",
        in_merged_bam = "results/mergedTechnicalReplicates/{sample}_in.bam",
        tx_counts=expand("results/mappedReadCounts/{sample}_treated_mappedReadCounts.txt", sample = samples_lst),
        in_counts=expand("results/mappedReadCounts/{sample}_input_mappedReadCounts.txt", sample = samples_lst),
    output:
        tx_downsampled_bam = "results/downSampledBams/{sample}_tx.bam",
        in_downsampled_bam = "results/downSampledBams/{sample}_in.bam",
    envmodules:
        config["samtools"]
    shell:
        """
        tx_min=$(cat {input.tx_counts} | sort -n | head -1)
        in_min=$(cat {input.in_counts} | sort -n | head -1)
        
        downSampleBam () {{
          fraction=$(samtools idxstats $2 | cut -f3 | awk -v ct=$1 'BEGIN {{total=0}} {{total += $1}} END {{print ct/total}}')
          if $fraction < 1
          then
          samtools view -@ 8 -b -s $fraction $2 > $3
          else
          cp $2 $3
          fi     
        }}
        
        downSampleBam ${{tx_min}} {input.tx_merged_bam} {output.tx_downsampled_bam}
        downSampleBam ${{in_min}} {input.in_merged_bam} {output.in_downsampled_bam}
        """

# merge downsampled samples
rule merged_downsampled_bams:
    input:
        expand("results/downSampledBams/{sample}_tx.bam",sample = samples_lst),
        expand("results/downSampledBams/{sample}_in.bam",sample = samples_lst),
    output:
        tx_merged_downsampled_bam = "results/mergedDownSampledBams/{sample}_tx.bam",
        in_merged_downsampled_bam = "results/mergedDownSampledBams/{sample}_in.bam",
    params:
        tx_bams=' '.join(expand("results/downSampledBams/{sample}_tx.bam",sample = set(samples_lst))),
        in_bams=' '.join(expand("results/downSampledBams/{sample}_in.bam",sample = set(samples_lst))),
    envmodules:
        config["samtools"]
    shell:
        """
        samtools merge -@ 8 {output.tx_merged_downsampled_bam} {params.tx_bams}
        samtools index -@ 8 {output.tx_merged_downsampled_bam}
        samtools merge -@ 8 {output.in_merged_downsampled_bam} {params.in_bams}
        samtools index -@ 8 {output.in_merged_downsampled_bam}
        """

## this didn't run.  I need to check the log file
# call narrow peaks with macs2 on merged bams
rule call_narrow_peaks_with_macs2_on_merged:
    input:
        tx_merged_downsampled_bam = "results/mergedDownSampledBams/{sample}_tx.bam",
        in_merged_downsampled_bam = "results/mergedDownSampledBams/{sample}_in.bam",
    output:
        "results/macs2_normalPeaks_merged/{sample}_" + str(config['macs2_minimum_FDR_cutoff']) + "_peaks.narrowPeak"
    params:
        effective_genome_size=config["effective_genome_size"],
        minimum_FDR_cutoff=str(config["macs2_minimum_FDR_cutoff"]),
        sample_name="{sample}"
    envmodules:
        config["macs2"]
    shell:
        """
        macs2 callpeak -t {input.tx_merged_downsampled_bam} -c {input.in_merged_downsampled_bam} -f BAMPE -g {params.effective_genome_size} -n {params.sample_name}_{params.minimum_FDR_cutoff} -q {params.minimum_FDR_cutoff} --outdir results/macs2_normalPeaks/
        """
        
  # get overlaps between peaks of merged sample and individual samples
  
  
  

