configfile: "config/config.yml"
import pandas as pd

##################################################################
##                    Define input functions                    ##
##################################################################

# this reads the CSV file and sets an index using the values in the "sample" column.
samples_table = pd.read_csv(config["samples_csv"]).set_index("sample", drop=False)
# convert all values in dataframe to strings
samples_table = samples_table.applymap(str)
# make a samples list
samples_lst = samples_table['sample'].to_list()
# make sets list
sets_lst = set(samples_table['set'].to_list())
# treatmentBam filename input function definition set to Python dictionary
def Bam_dict_from_sample(wildcards):
  return {
    "txBam": samples_table.loc[wildcards.sample, "treatmentBam"],
    "inBam": samples_table.loc[wildcards.sample, "inputBam"]
  }
# function that returns dict of filenames/paths joined (ie space-separated) for a set of interest
def CountFiles_dict_from_set(set):
  sample_lst = samples_table.loc[samples_table["set"] == str(set),"sample"].to_list()
  tx_counts_files_list = expand('results/mappedReadCounts/{sample}_treated_mappedReadCounts.txt', sample = sample_lst)
  in_counts_files_list = expand('results/mappedReadCounts/{sample}_input_mappedReadCounts.txt', sample = sample_lst)
  tx_string = ' '.join([str(item) for item in tx_counts_files_list])
  in_string = ' '.join([str(item) for item in in_counts_files_list])
  return [tx_string, in_string]
  



##################################################################
##                           rules                              ##
##################################################################

# to run snakemake without explicitly requesting any output files on the command line, we must request output files in the first rule. Therefore we include this otherwise useless rule here  
rule all:
    input:
        expand("results/macs2_normalPeaks/{sample}_" + str(config['macs2_minimum_FDR_cutoff']) + "_peaks.narrowPeak", sample = samples_lst),
        expand("results/mappedReadCounts/{sample}_treated_mappedReadCounts.txt", sample = samples_lst),
        expand("results/mappedReadCounts/{sample}_input_mappedReadCounts.txt", sample = samples_lst),
        expand("results/minMappedReadCounts/{set}_treated_minMappedReadCounts.txt", set = sets_lst),
        expand("results/minMappedReadCounts/{set}_input_minMappedReadCounts.txt", set = sets_lst),


        
# call narrow peaks with macs2
rule call_narrow_peaks_with_macs2:
    input:
        unpack(Bam_dict_from_sample)   # <--- we need to wrap our input function inside a special Snakemake function called unpack() which turns the dict into a collection of named inputs
    output:
        "results/macs2_normalPeaks/{sample}_" + str(config['macs2_minimum_FDR_cutoff']) + "_peaks.narrowPeak"
    params:
        effective_genome_size=config["effective_genome_size"],
        minimum_FDR_cutoff=str(config["macs2_minimum_FDR_cutoff"]),
        sample_name="{sample}"
    envmodules:
        config["macs2"]
    log: "results/logs/snakelogs/call_narrow_peaks_with_macs2.{sample}_q" + str(config["macs2_minimum_FDR_cutoff"]) + ".log"
    shell:
        """
        macs2 callpeak -t {input.txBam} -c {input.inBam} -f BAMPE -g {params.effective_genome_size} -n {params.sample_name}_{params.minimum_FDR_cutoff} -q {params.minimum_FDR_cutoff} --outdir results/macs2_normalPeaks/
        """

# write read counts for each bam to a file
rule write_read_counts:
    input:
        unpack(Bam_dict_from_sample)   # <--- we need to wrap our input function inside a special Snakemake function called unpack() which turns the dict into a collection of named inputs
    output:
        treatmentCountFile="results/mappedReadCounts/{sample}_treated_mappedReadCounts.txt",
        inputCountFile="results/mappedReadCounts/{sample}_input_mappedReadCounts.txt",
    envmodules:
        config["samtools"]
    shell:
        """
        samtools idxstats {input.txBam} | awk -F '\t' '{{s+=$3}}END{{print s}}' > {output.treatmentCountFile}
        samtools idxstats {input.inBam} | awk -F '\t' '{{s+=$3}}END{{print s}}' > {output.inputCountFile}
        """
 
# get min read counts for each set
rule get_set_min_read_counts:
    input:
        expand("results/mappedReadCounts/{sample}_treated_mappedReadCounts.txt", sample = samples_lst),
        expand("results/mappedReadCounts/{sample}_input_mappedReadCounts.txt", sample = samples_lst),
    output:
        treatmentMinCountFile="results/minMappedReadCounts/{set}_treated_minMappedReadCounts.txt",
        inputMinCountFile="results/minMappedReadCounts/{set}_input_minMappedReadCounts.txt",
    params:
        tx_count_files=CountFiles_dict_from_set(str({set}))[0],
        in_count_files=CountFiles_dict_from_set({set})[1],
    envmodules:
        config["samtools"]
    shell:
        """
        cat {params.tx_count_files} > {output.treatmentMinCountFile}
        cat {params.in_count_files} > {output.inputMinCountFile}
        """
